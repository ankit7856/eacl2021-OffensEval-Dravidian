{"cells":[{"cell_type":"markdown","metadata":{"id":"WH150tMzDtun"},"source":["# Connect G-Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52601,"status":"ok","timestamp":1610609187034,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"LGw44gb-D6Ho","outputId":"76dc0211-95a2-48c2-a9c2-cd74dc287094"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"FWNUAn35h4LJ"},"source":["# Code"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2758,"status":"ok","timestamp":1610609192596,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"YjhojOuWghjR"},"outputs":[],"source":["# !git clone https://github.com/murali1996/codemixed"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15632,"status":"ok","timestamp":1610609206016,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"F8uPvZUYgzpJ","outputId":"b332ef77-6fd5-4bfc-c7d9-12cf993a2eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["User name: murali1996\n","Password: ··········\n","Repo name: codemixed\n"]}],"source":["import os\n","from getpass import getpass\n","import urllib\n","\n","user = input('User name: ')\n","password = getpass('Password: ')\n","password = urllib.parse.quote(password) # your password is converted into url format\n","repo_name = input('Repo name: ')\n","\n","cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n","\n","os.system(cmd_string)\n","cmd_string, password = \"\", \"\" # removing the password from the variable"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1499,"status":"ok","timestamp":1610609209089,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"pT3wYufwhpHP","outputId":"926acd7f-18d9-4597-8fed-5b2725557d35"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/codemixed\n"]}],"source":["%cd /content/codemixed"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":80363,"status":"ok","timestamp":1610609289398,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"7QRs73KmkOEK","outputId":"02cabdf2-c650-4782-a5a3-59debfe525e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sklearn~=0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.0)\n","Collecting jsonlines~=1.2.0\n","  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n","Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 14.3MB/s \n","\u001b[?25hCollecting transformers~=3.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 25.0MB/s \n","\u001b[?25hCollecting fasttext~=0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n","\u001b[?25hCollecting wordsegment~=1.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n","\u001b[K     |████████████████████████████████| 4.8MB 44.2MB/s \n","\u001b[?25hCollecting seqeval~=1.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hCollecting google-cloud-translate==2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/f9/484dba1aa2e222c00884c36d323885abb3283dc4bfc6b75acc4fec1de77c/google_cloud_translate-2.0.1-py2.py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.2MB/s \n","\u001b[?25hRequirement already satisfied: pandas~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.5)\n","Collecting numpy~=1.18.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n","\u001b[K     |████████████████████████████████| 20.1MB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: torch~=1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (1.7.0+cu101)\n","Collecting tqdm~=4.43.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n","\u001b[?25hCollecting twitter-text-python~=1.1.1\n","  Downloading https://files.pythonhosted.org/packages/29/a9/3d9cc947dea07e42f55a3c9de741ceeea766f841bc08297605a6370dfca0/twitter-text-python-1.1.1.tar.gz\n","Collecting typing~=3.7.4.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/d9/6eebe19d46bd05360c9a9aae822e67a80f9242aabbfc58b641b957546607/typing-3.7.4.3.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n","\u001b[?25hCollecting testtools~=2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/d5/d0e0d16478fd4700694673518842be3c159fa08230e377f5f8570c170bbd/testtools-2.4.0-py2.py3-none-any.whl (185kB)\n","\u001b[K     |████████████████████████████████| 194kB 59.1MB/s \n","\u001b[?25hCollecting six~=1.14.0\n","  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n","Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (1.4.1)\n","Collecting argparse~=1.4.0\n","  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n","Collecting scikit-learn~=0.23.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 47.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses~=0.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.8)\n","Collecting requests~=2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[?25hCollecting matplotlib~=3.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/43/2bd63467490036697e7be71444fafc7b236923d614d4521979a200c6b559/matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n","\u001b[K     |████████████████████████████████| 11.6MB 41.1MB/s \n","\u001b[?25hCollecting nltk~=3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 46.3MB/s \n","\u001b[?25hCollecting tweepy~=3.9.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Collecting Unidecode~=1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n","\u001b[K     |████████████████████████████████| 245kB 55.1MB/s \n","\u001b[?25hCollecting seaborn~=0.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e6/54aaaafd0b87f51dfba92ba73da94151aa3bc179e5fe88fc5dfb3038e860/seaborn-0.10.1-py3-none-any.whl (215kB)\n","\u001b[K     |████████████████████████████████| 225kB 32.1MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert-\u003e-r requirements.txt (line 3)) (2019.12.20)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/da/8d9a790f134b36f4e3c53f0fca330a6917a3091c61cb74d4ab1e15ee8940/boto3-1.16.54-py2.py3-none-any.whl (130kB)\n","\u001b[K     |████████████████████████████████| 133kB 58.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1-\u003e-r requirements.txt (line 4)) (20.8)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 46.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1-\u003e-r requirements.txt (line 4)) (3.0.12)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 47.8MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1-\u003e-r requirements.txt (line 4)) (3.12.4)\n","Requirement already satisfied: pybind11\u003e=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext~=0.9.2-\u003e-r requirements.txt (line 5)) (2.6.1)\n","Requirement already satisfied: setuptools\u003e=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext~=0.9.2-\u003e-r requirements.txt (line 5)) (51.1.1)\n","Requirement already satisfied: google-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (1.16.0)\n","Collecting google-cloud-core\u003c2.0dev,\u003e=1.1.0\n","  Downloading https://files.pythonhosted.org/packages/36/82/d54bdbdbae02c66ec26c97eb684cfb27af82b3e286497625b815c4741792/google_cloud_core-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.1.0-\u003e-r requirements.txt (line 9)) (2018.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.1.0-\u003e-r requirements.txt (line 9)) (2.8.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch~=1.7.0-\u003e-r requirements.txt (line 11)) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch~=1.7.0-\u003e-r requirements.txt (line 11)) (3.7.4.3)\n","Collecting pbr\u003e=0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n","\u001b[K     |████████████████████████████████| 112kB 54.4MB/s \n","\u001b[?25hCollecting python-mimeparse\n","  Downloading https://files.pythonhosted.org/packages/26/2e/03bce213a9bf02a2750dcb04e761785e9c763fc11071edc4b447eacbb842/python_mimeparse-1.6.0-py2.py3-none-any.whl\n","Collecting extras\u003e=1.0.0\n","  Downloading https://files.pythonhosted.org/packages/03/e9/e915af1f97914cd0bc021e125fd1bfd4106de614a275e4b6866dd9a209ac/extras-1.0.0-py2.py3-none-any.whl\n","Collecting unittest2\u003e=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/20/7f0f433060a962200b7272b8c12ba90ef5b903e218174301d0abfd523813/unittest2-1.1.0-py2.py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n","\u001b[?25hCollecting fixtures\u003e=1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/28/7eed6bf76792f418029a18d5b2ace87ce7562927cdd00f1cefe481cd148f/fixtures-3.0.0-py2.py3-none-any.whl (67kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n","\u001b[?25hCollecting traceback2\n","  Downloading https://files.pythonhosted.org/packages/17/0a/6ac05a3723017a967193456a2efa0aa9ac4b51456891af1e2353bb9de21e/traceback2-1.4.0-py2.py3-none-any.whl\n","Collecting threadpoolctl\u003e=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.23.2-\u003e-r requirements.txt (line 19)) (1.0.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.24.0-\u003e-r requirements.txt (line 21)) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.24.0-\u003e-r requirements.txt (line 21)) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.24.0-\u003e-r requirements.txt (line 21)) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.24.0-\u003e-r requirements.txt (line 21)) (2.10)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.3.1-\u003e-r requirements.txt (line 22)) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.3.1-\u003e-r requirements.txt (line 22)) (2.4.7)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.3.1-\u003e-r requirements.txt (line 22)) (7.0.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.3.1-\u003e-r requirements.txt (line 22)) (0.10.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk~=3.5-\u003e-r requirements.txt (line 23)) (7.1.2)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy~=3.9.0-\u003e-r requirements.txt (line 24)) (1.3.0)\n","Collecting jmespath\u003c1.0.0,\u003e=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting s3transfer\u003c0.4.0,\u003e=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n","\u001b[?25hCollecting botocore\u003c1.20.0,\u003e=1.19.54\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/b5/c9c91206814b35b18d8e187cea17a084a1ab24a8596764d2549de900ac83/botocore-1.19.54-py2.py3-none-any.whl (7.2MB)\n","\u001b[K     |████████████████████████████████| 7.2MB 48.2MB/s \n","\u001b[?25hRequirement already satisfied: google-auth\u003c2.0dev,\u003e=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (1.17.2)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (1.52.0)\n","Requirement already satisfied: grpcio\u003c2.0dev,\u003e=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (1.32.0)\n","Collecting linecache2\n","  Downloading https://files.pythonhosted.org/packages/c7/a3/c5da2a44c85bfbb6eebcfc1dde24933f8704441b98fdde6528f4831757a6/linecache2-1.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003etweepy~=3.9.0-\u003e-r requirements.txt (line 24)) (3.1.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4; python_version \u003e= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth\u003c2.0dev,\u003e=0.4.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (4.6)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth\u003c2.0dev,\u003e=0.4.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (4.2.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth\u003c2.0dev,\u003e=0.4.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (0.2.8)\n","Requirement already satisfied: pyasn1\u003e=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa\u003c5,\u003e=3.1.4; python_version \u003e= \"3\"-\u003egoogle-auth\u003c2.0dev,\u003e=0.4.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.15.0-\u003egoogle-cloud-translate==2.0.1-\u003e-r requirements.txt (line 8)) (0.4.8)\n","Building wheels for collected packages: fasttext, seqeval, twitter-text-python, typing, nltk, sacremoses\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3045368 sha256=df33e6a8d64dca7d2d4528e022a9717853a7668cc81ee6d745b2ed43af25b709\n","  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=d4da58f04801e0def5fe113d707493a5528c71a17a0400a2d35ef95b776ca745\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","  Building wheel for twitter-text-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for twitter-text-python: filename=twitter_text_python-1.1.1-cp36-none-any.whl size=10045 sha256=0c0687bb96a4915ab641537bb41b8e45133e09b69743b7207a6ba6d5b6285a0a\n","  Stored in directory: /root/.cache/pip/wheels/08/a4/8b/fc095442f760d0103f128b052ca90c46485077541c5a6a86bc\n","  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for typing: filename=typing-3.7.4.3-cp36-none-any.whl size=26310 sha256=6fa92db1ecf988a8dc4c280f6b8a8a299586d57d7c4b00acb3611986e0e5d484\n","  Stored in directory: /root/.cache/pip/wheels/2d/04/41/8e1836e79581989c22eebac3f4e70aaac9af07b0908da173be\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=540d92a8d26adb0277dca1607c8eec3490d8464858e1c16cc1a88575922504a1\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f032d383da75c1d4bf1a67a4a37df0bde89bac5976944aee73183684cd71d0ee\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built fasttext seqeval twitter-text-python typing nltk sacremoses\n","\u001b[31mERROR: tensorflow 2.4.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client\u003e=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-cloud-core 1.5.0 has requirement google-api-core\u003c2.0.0dev,\u003e=1.21.0, but you'll have google-api-core 1.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug\u003c0.2.7,\u003e=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.19.54 has requirement urllib3\u003c1.27,\u003e=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: six, jsonlines, tqdm, numpy, jmespath, botocore, s3transfer, boto3, requests, pytorch-pretrained-bert, sentencepiece, sacremoses, tokenizers, transformers, fasttext, wordsegment, threadpoolctl, scikit-learn, seqeval, google-cloud-core, google-cloud-translate, twitter-text-python, typing, pbr, python-mimeparse, extras, argparse, linecache2, traceback2, unittest2, fixtures, testtools, matplotlib, nltk, tweepy, Unidecode, seaborn\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: google-cloud-core 1.0.3\n","    Uninstalling google-cloud-core-1.0.3:\n","      Successfully uninstalled google-cloud-core-1.0.3\n","  Found existing installation: google-cloud-translate 1.5.0\n","    Uninstalling google-cloud-translate-1.5.0:\n","      Successfully uninstalled google-cloud-translate-1.5.0\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: seaborn 0.11.1\n","    Uninstalling seaborn-0.11.1:\n","      Successfully uninstalled seaborn-0.11.1\n","Successfully installed Unidecode-1.1.2 argparse-1.4.0 boto3-1.16.54 botocore-1.19.54 extras-1.0.0 fasttext-0.9.2 fixtures-3.0.0 google-cloud-core-1.5.0 google-cloud-translate-2.0.1 jmespath-0.10.0 jsonlines-1.2.0 linecache2-1.0.0 matplotlib-3.3.3 nltk-3.5 numpy-1.18.5 pbr-5.5.1 python-mimeparse-1.6.0 pytorch-pretrained-bert-0.6.2 requests-2.24.0 s3transfer-0.3.4 sacremoses-0.0.43 scikit-learn-0.23.2 seaborn-0.10.1 sentencepiece-0.1.91 seqeval-1.2.2 six-1.14.0 testtools-2.4.0 threadpoolctl-2.1.0 tokenizers-0.9.3 tqdm-4.43.0 traceback2-1.4.0 transformers-3.5.1 tweepy-3.9.0 twitter-text-python-1.1.1 typing-3.7.4.3 unittest2-1.1.0 wordsegment-1.3.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","google","matplotlib","mpl_toolkits","numpy","six","typing"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79346,"status":"ok","timestamp":1610609289399,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"q8KhlOKEuiO_","outputId":"9764c01a-a5dc-4fc4-fea9-d28c63444660"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/codemixed\n"]}],"source":["%cd /content/codemixed"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90995,"status":"ok","timestamp":1610609302356,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"nVZsFyNthLhj","outputId":"a26a8133-218f-4132-e561-1efde3976b41"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/codemixed/datasets/eacl2021\n","./offeval/tamil created\n","./offeval/malayalam created\n","./offeval/kannada created\n","complete\n","offeval/tamil/train.tsv 35139\n","n_trimmed = 465 to max len 300\n","offeval/tamil/dev.tsv 4388\n","n_trimmed = 529 to max len 300\n","offeval/tamil/test.tsv 4392\n","n_trimmed = 581 to max len 300\n","total train lines obtained: 39527 with 581 trimmed to max len 300\n","total train lines written: 38993+550=39543\n","total test lines obtained: 4392\n","total test lines written: 4339+53=4392\n","offeval/malayalam/train.tsv 16010\n","n_trimmed = 96 to max len 300\n","offeval/malayalam/dev.tsv 1999\n","n_trimmed = 111 to max len 300\n","offeval/malayalam/test.tsv 2001\n","n_trimmed = 126 to max len 300\n","total train lines obtained: 18009 with 126 trimmed to max len 300\n","total train lines written: 17898+134=18032\n","total test lines obtained: 2001\n","total test lines written: 1986+18=2004\n","offeval/kannada/train.tsv 6217\n","n_trimmed = 53 to max len 300\n","offeval/kannada/dev.tsv 777\n","n_trimmed = 63 to max len 300\n","offeval/kannada/test.tsv 778\n","n_trimmed = 69 to max len 300\n","total train lines obtained: 6994 with 69 trimmed to max len 300\n","total train lines written: 6931+66=6997\n","total test lines obtained: 778\n","total test lines written: 772+8=780\n","train.jsonl\n","# lines: 6217\n","# lines: 4695\n","# lines: 1151\n","# lines: 4695\n","dev.jsonl\n","# lines: 777\n","# lines: 586\n","# lines: 160\n","# lines: 586\n","test.jsonl\n","# lines: 778\n","# lines: 778\n","# lines: 778\n","# lines: 778\n","train.jsonl\n","# lines: 35139\n","# lines: 33685\n","# lines: 8260\n","# lines: 33685\n","dev.jsonl\n","# lines: 4388\n","# lines: 4216\n","# lines: 1023\n","# lines: 4216\n","test.jsonl\n","# lines: 4392\n","# lines: 4392\n","# lines: 4392\n","# lines: 4392\n","train.jsonl\n","# lines: 16010\n","# lines: 14723\n","# lines: 570\n","# lines: 14723\n","dev.jsonl\n","# lines: 1999\n","# lines: 1836\n","# lines: 57\n","# lines: 1836\n","test.jsonl\n","# lines: 2001\n","# lines: 2001\n","# lines: 2001\n","# lines: 2001\n","complete\n"]}],"source":["%cd datasets/eacl2021\n","!bash make_data.sh"]},{"cell_type":"markdown","metadata":{"id":"ZtHmBRJ3wpVw"},"source":["# xlm w/ MLM-pretrained"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":905,"status":"ok","timestamp":1610561077668,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"kHgODcBuhmaG","outputId":"d42b4923-07c9-4315-d1f5-94f12598aa02"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/codemixed/scripts\n"]}],"source":["%cd /content/codemixed/scripts/"]},{"cell_type":"markdown","metadata":{"id":"3jZd5j306FCv"},"source":["### run-1"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633631,"status":"ok","timestamp":1610561716657,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"-juekeEM5gAk","outputId":"bbd5bca0-45d0-4efc-930c-9ee1e93d7334"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 18:04:49.241627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/train.jsonl, mode:train, #examples:6217\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/test.jsonl, mode:test, #examples:778\n","100% 6217/6217 [00:00\u003c00:00, 1841524.57it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 3544, 'not-Kannada': 1522, 'Offensive_Targeted_Insult_Group': 329, 'Offensive_Targeted_Insult_Other': 123, 'Offensive_Targeted_Insult_Individual': 487, 'Offensive_Untargetede': 212}\n","\n","Downloading: 100% 512/512 [00:00\u003c00:00, 778kB/s]\n","Downloading: 100% 5.07M/5.07M [00:00\u003c00:00, 59.8MB/s]\n","Downloading: 100% 1.12G/1.12G [00:14\u003c00:00, 77.4MB/s]\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/xlm-roberta-base/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/xlm-roberta-base//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","epoch:  0\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [\u003e              ] 0% || batch_time: 0.3213 || batch_loss: 1.7545 || avg_batch_loss: 1.7545 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3900 || batch_loss: 0.6715 || avg_batch_loss: 1.0725 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2750 || batch_loss: 1.0274 || avg_batch_loss: 1.0724 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0523 || batch_loss: 0.6904 || avg_batch_loss: 0.9081 || batch_acc: 0.8125 || avg_batch_acc: 0.7096 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0314 || batch_loss: 1.1431 || avg_batch_loss: 0.9129 || batch_acc: 0.3750 || avg_batch_acc: 0.7028 \n","\n"," Validation Complete\n","Validation avg_loss: 0.9129 and acc: 0.7091\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.7061    0.8685    0.7789       426\n","           1     0.7130    0.8063    0.7568       191\n","           2     0.0000    0.0000    0.0000        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.7297    0.4091    0.5243        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7091       777\n","   macro avg     0.3581    0.3473    0.3433       777\n","weighted avg     0.6244    0.7091    0.6576       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.3471 || batch_loss: 0.4867 || avg_batch_loss: 0.8151 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3447 || batch_loss: 0.7285 || avg_batch_loss: 0.8148 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0523 || batch_loss: 0.9481 || avg_batch_loss: 0.8843 || batch_acc: 0.6250 || avg_batch_acc: 0.6979 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0322 || batch_loss: 1.1079 || avg_batch_loss: 0.8889 || batch_acc: 0.3125 || avg_batch_acc: 0.6901 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8889 and acc: 0.6963\n","              precision    recall  f1-score   support\n","\n","           0     0.6803    0.8991    0.7745       426\n","           1     0.7637    0.7277    0.7453       191\n","           2     1.0000    0.0444    0.0851        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5667    0.2576    0.3542        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.6963       777\n","   macro avg     0.5018    0.3215    0.3265       777\n","weighted avg     0.6668    0.6963    0.6429       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 0(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  2\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.4308 || batch_loss: 0.4966 || avg_batch_loss: 0.7305 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2652 || batch_loss: 0.6175 || avg_batch_loss: 0.7303 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0520 || batch_loss: 0.9775 || avg_batch_loss: 0.8313 || batch_acc: 0.6875 || avg_batch_acc: 0.7057 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0307 || batch_loss: 0.8028 || avg_batch_loss: 0.8307 || batch_acc: 0.3750 || avg_batch_acc: 0.6990 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8307 and acc: 0.7053\n","              precision    recall  f1-score   support\n","\n","           0     0.7258    0.8451    0.7809       426\n","           1     0.7368    0.7330    0.7349       191\n","           2     0.3750    0.2000    0.2609        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5821    0.5909    0.5865        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7053       777\n","   macro avg     0.4033    0.3948    0.3939       777\n","weighted avg     0.6502    0.7053    0.6737       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 0(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  3\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.4519 || batch_loss: 0.7840 || avg_batch_loss: 0.6431 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2712 || batch_loss: 0.9273 || avg_batch_loss: 0.6438 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0530 || batch_loss: 0.9153 || avg_batch_loss: 0.8354 || batch_acc: 0.7500 || avg_batch_acc: 0.7188 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0326 || batch_loss: 0.6945 || avg_batch_loss: 0.8325 || batch_acc: 0.3125 || avg_batch_acc: 0.7105 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8325 and acc: 0.7169\n","              precision    recall  f1-score   support\n","\n","           0     0.7345    0.8638    0.7940       426\n","           1     0.7337    0.7644    0.7487       191\n","           2     0.4194    0.2889    0.3421        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.6522    0.4545    0.5357        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7169       777\n","   macro avg     0.4233    0.3953    0.4034       777\n","weighted avg     0.6627    0.7169    0.6847       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/model.pth.tar in epoch 3\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/label_vocab.json in epoch 3\n","\n","\n","################\n","epoch:  4\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 99% || batch_time: 0.0497 || batch_loss: 0.2698 || avg_batch_loss: 0.5894 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 99% || batch_time: 0.0596 || batch_loss: 0.8275 || avg_batch_loss: 0.5902 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.5312 || batch_loss: 0.6982 || avg_batch_loss: 0.5905 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2615 || batch_loss: 0.2805 || avg_batch_loss: 0.5897 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0512 || batch_loss: 0.9658 || avg_batch_loss: 0.8459 || batch_acc: 0.6875 || avg_batch_acc: 0.7253 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0310 || batch_loss: 0.6187 || avg_batch_loss: 0.8412 || batch_acc: 0.4375 || avg_batch_acc: 0.7194 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8412 and acc: 0.7259\n","              precision    recall  f1-score   support\n","\n","           0     0.7568    0.8474    0.7996       426\n","           1     0.7356    0.8010    0.7669       191\n","           2     0.4324    0.3556    0.3902        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.6182    0.5152    0.5620        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7259       777\n","   macro avg     0.4238    0.4199    0.4198       777\n","weighted avg     0.6733    0.7259    0.6972       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/model.pth.tar in epoch 4\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/label_vocab.json in epoch 4\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0529 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0303 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/2021-01-13_18:15:05.082780\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw\n","len of test data: 778\n","n_batches of test data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0331 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0286 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/2021-01-13_18:15:05.082780\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82874,"status":"ok","timestamp":1610570710073,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"q7UhZ2KWfLCK","outputId":"95b87f8d-ac50-4c16-bc6e-fcc52692cb5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:43:50.712618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0483 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0294 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw/2021-01-13_20:45:05.614655\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/xlm-roberta-base/text_raw"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1447597,"status":"ok","timestamp":1610563164275,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"dMR9F3Jy7kmL","outputId":"e0d836f7-3e24-41b2-c5f6-69032956fb37"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 18:15:25.064341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/train.jsonl, mode:train, #examples:16010\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/test.jsonl, mode:test, #examples:2001\n","100% 16010/16010 [00:00\u003c00:00, 1995684.95it/s]\n","Total tokens found: 5\n","token_freq:\n","{'Not_offensive': 14153, 'Offensive_Targeted_Insult_Individual': 239, 'not-malayalam': 1287, 'Offensive_Targeted_Insult_Group': 140, 'Offensive_Untargetede': 191}\n","\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/xlm-roberta-base/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/xlm-roberta-base//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (278047493, 278047493)\n","\n","\n","################\n","epoch:  0\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [\u003e              ] 0% || batch_time: 0.1087 || batch_loss: 1.7451 || avg_batch_loss: 1.7451 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3951 || batch_loss: 0.0440 || avg_batch_loss: 0.4108 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2854 || batch_loss: 0.0651 || avg_batch_loss: 0.4104 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0710 || batch_loss: 0.0364 || avg_batch_loss: 0.2544 || batch_acc: 1.0000 || avg_batch_acc: 0.9345 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0621 || batch_loss: 0.1300 || avg_batch_loss: 0.2534 || batch_acc: 0.8750 || avg_batch_acc: 0.9340 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2534 and acc: 0.9345\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.9508    0.9770    0.9637      1779\n","           1     0.0000    0.0000    0.0000        24\n","           2     0.7602    0.7975    0.7784       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.0000    0.0000    0.0000        20\n","\n","    accuracy                         0.9345      1999\n","   macro avg     0.3422    0.3549    0.3484      1999\n","weighted avg     0.9081    0.9345    0.9211      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.3431 || batch_loss: 0.2057 || avg_batch_loss: 0.2435 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2790 || batch_loss: 0.4077 || avg_batch_loss: 0.2437 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0700 || batch_loss: 0.0835 || avg_batch_loss: 0.2004 || batch_acc: 1.0000 || avg_batch_acc: 0.9471 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0616 || batch_loss: 0.1364 || avg_batch_loss: 0.1999 || batch_acc: 0.9375 || avg_batch_acc: 0.9470 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1999 and acc: 0.9475\n","              precision    recall  f1-score   support\n","\n","           0     0.9544    0.9893    0.9716      1779\n","           1     0.0000    0.0000    0.0000        24\n","           2     0.8881    0.7791    0.8301       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.5833    0.3500    0.4375        20\n","\n","    accuracy                         0.9475      1999\n","   macro avg     0.4852    0.4237    0.4478      1999\n","weighted avg     0.9277    0.9475    0.9367      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.3364 || batch_loss: 0.0144 || avg_batch_loss: 0.1794 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2875 || batch_loss: 0.0086 || avg_batch_loss: 0.1792 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0689 || batch_loss: 0.0069 || avg_batch_loss: 0.1636 || batch_acc: 1.0000 || avg_batch_acc: 0.9567 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0614 || batch_loss: 0.0611 || avg_batch_loss: 0.1628 || batch_acc: 0.8750 || avg_batch_acc: 0.9560 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1628 and acc: 0.9565\n","              precision    recall  f1-score   support\n","\n","           0     0.9650    0.9904    0.9775      1779\n","           1     1.0000    0.0417    0.0800        24\n","           2     0.9045    0.8712    0.8875       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.4667    0.3500    0.4000        20\n","\n","    accuracy                         0.9565      1999\n","   macro avg     0.6672    0.4507    0.4690      1999\n","weighted avg     0.9492    0.9565    0.9473      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.4232 || batch_loss: 0.0501 || avg_batch_loss: 0.1208 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3049 || batch_loss: 0.0078 || avg_batch_loss: 0.1207 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0682 || batch_loss: 0.0024 || avg_batch_loss: 0.1589 || batch_acc: 1.0000 || avg_batch_acc: 0.9622 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0664 || batch_loss: 0.0493 || avg_batch_loss: 0.1580 || batch_acc: 0.9375 || avg_batch_acc: 0.9620 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1580 and acc: 0.9625\n","              precision    recall  f1-score   support\n","\n","           0     0.9745    0.9888    0.9816      1779\n","           1     0.6429    0.3750    0.4737        24\n","           2     0.9119    0.8896    0.9006       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.5238    0.5500    0.5366        20\n","\n","    accuracy                         0.9625      1999\n","   macro avg     0.6106    0.5607    0.5785      1999\n","weighted avg     0.9546    0.9625    0.9580      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/model.pth.tar in epoch 3\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/label_vocab.json in epoch 3\n","\n","\n","################\n","epoch:  4\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.2280 || batch_loss: 0.2035 || avg_batch_loss: 0.0895 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.0543 || batch_loss: 0.0152 || avg_batch_loss: 0.0893 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.5227 || batch_loss: 0.0180 || avg_batch_loss: 0.0893 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2842 || batch_loss: 0.0308 || avg_batch_loss: 0.0892 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0692 || batch_loss: 0.0024 || avg_batch_loss: 0.1618 || batch_acc: 1.0000 || avg_batch_acc: 0.9597 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0633 || batch_loss: 0.0289 || avg_batch_loss: 0.1607 || batch_acc: 0.9375 || avg_batch_acc: 0.9595 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1607 and acc: 0.9600\n","              precision    recall  f1-score   support\n","\n","           0     0.9777    0.9837    0.9807      1779\n","           1     0.4500    0.3750    0.4091        24\n","           2     0.9080    0.9080    0.9080       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.4615    0.6000    0.5217        20\n","\n","    accuracy                         0.9600      1999\n","   macro avg     0.5594    0.5733    0.5639      1999\n","weighted avg     0.9541    0.9600    0.9569      1999\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 3(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0699 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0603 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/2021-01-13_18:39:05.015462\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw\n","len of test data: 2001\n","n_batches of test data: 126\n","Percent: [--------------\u003e] 99% || batch_time: 0.0408 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0282 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/2021-01-13_18:39:05.015462\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/malayalam --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86126,"status":"ok","timestamp":1610570796214,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"Jwk-ri1-fVJX","outputId":"3640528a-600f-4c6f-b9d1-4fbb7625cde5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:45:13.378347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","number of parameters (all, trainable) in your model: (278047493, 278047493)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.0656 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0600 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw/2021-01-13_20:46:27.970692\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/malayalam --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/xlm-roberta-base/text_raw"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4692751,"status":"ok","timestamp":1610566409435,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"dQMTyRCB7m5V","outputId":"2213c68f-d0ef-4e8e-a909-1e610c95e50c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 18:39:29.004300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/train.jsonl, mode:train, #examples:35139\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/test.jsonl, mode:test, #examples:4392\n","100% 35139/35139 [00:00\u003c00:00, 1858112.79it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 25425, 'not-Tamil': 1454, 'Offensive_Targeted_Insult_Other': 454, 'Offensive_Targeted_Insult_Group': 2557, 'Offensive_Untargetede': 2906, 'Offensive_Targeted_Insult_Individual': 2343}\n","\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","epoch:  0\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [\u003e              ] 0% || batch_time: 0.0877 || batch_loss: 1.6794 || avg_batch_loss: 1.6794 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.4754 || batch_loss: 0.8397 || avg_batch_loss: 0.7785 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2640 || batch_loss: 0.1648 || avg_batch_loss: 0.7782 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0492 || batch_loss: 0.5667 || avg_batch_loss: 0.6314 || batch_acc: 0.6875 || avg_batch_acc: 0.7844 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0182 || batch_loss: 1.0193 || avg_batch_loss: 0.6328 || batch_acc: 0.1875 || avg_batch_acc: 0.7823 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6328 and acc: 0.7844\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.8212    0.9640    0.8869      3193\n","           1     0.8710    0.7849    0.8257       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.4430    0.1186    0.1872       295\n","           4     0.4681    0.3090    0.3723       356\n","           5     0.4912    0.2736    0.3515       307\n","\n","    accuracy                         0.7844      4388\n","   macro avg     0.5158    0.4084    0.4372      4388\n","weighted avg     0.7339    0.7844    0.7451      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3966 || batch_loss: 0.3701 || avg_batch_loss: 0.5902 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2561 || batch_loss: 0.5203 || avg_batch_loss: 0.5902 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0488 || batch_loss: 0.5947 || avg_batch_loss: 0.6291 || batch_acc: 0.6875 || avg_batch_acc: 0.7940 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0190 || batch_loss: 0.9139 || avg_batch_loss: 0.6301 || batch_acc: 0.1875 || avg_batch_acc: 0.7918 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6301 and acc: 0.7940\n","              precision    recall  f1-score   support\n","\n","           0     0.8416    0.9536    0.8941      3193\n","           1     0.8980    0.7674    0.8276       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.4182    0.3119    0.3573       295\n","           4     0.5105    0.3427    0.4101       356\n","           5     0.5671    0.3029    0.3949       307\n","\n","    accuracy                         0.7940      4388\n","   macro avg     0.5392    0.4464    0.4807      4388\n","weighted avg     0.7568    0.7940    0.7680      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3585 || batch_loss: 0.1137 || avg_batch_loss: 0.5015 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2585 || batch_loss: 0.2619 || avg_batch_loss: 0.5014 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0489 || batch_loss: 0.6308 || avg_batch_loss: 0.6544 || batch_acc: 0.6250 || avg_batch_acc: 0.7929 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0163 || batch_loss: 0.8112 || avg_batch_loss: 0.6549 || batch_acc: 0.1875 || avg_batch_acc: 0.7907 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6549 and acc: 0.7928\n","              precision    recall  f1-score   support\n","\n","           0     0.8523    0.9414    0.8946      3193\n","           1     0.8824    0.7849    0.8308       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.4710    0.2203    0.3002       295\n","           4     0.4463    0.4438    0.4451       356\n","           5     0.5324    0.3746    0.4398       307\n","\n","    accuracy                         0.7928      4388\n","   macro avg     0.5307    0.4608    0.4851      4388\n","weighted avg     0.7599    0.7928    0.7706      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  3\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3269 || batch_loss: 0.5593 || avg_batch_loss: 0.4311 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2627 || batch_loss: 1.1285 || avg_batch_loss: 0.4314 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0467 || batch_loss: 0.8911 || avg_batch_loss: 0.6951 || batch_acc: 0.5625 || avg_batch_acc: 0.7911 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0157 || batch_loss: 0.8399 || avg_batch_loss: 0.6956 || batch_acc: 0.1875 || avg_batch_acc: 0.7889 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6956 and acc: 0.7910\n","              precision    recall  f1-score   support\n","\n","           0     0.8710    0.9220    0.8958      3193\n","           1     0.8671    0.7965    0.8303       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3795    0.4271    0.4019       295\n","           4     0.4816    0.4410    0.4604       356\n","           5     0.5573    0.3485    0.4289       307\n","\n","    accuracy                         0.7910      4388\n","   macro avg     0.5261    0.4892    0.5029      4388\n","weighted avg     0.7714    0.7910    0.7788      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.1349 || batch_loss: 0.1846 || avg_batch_loss: 0.3749 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.0611 || batch_loss: 0.1150 || avg_batch_loss: 0.3749 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2232 || batch_loss: 0.2337 || avg_batch_loss: 0.3748 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.4119 || batch_loss: 0.1807 || avg_batch_loss: 0.3747 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2659 || batch_loss: 0.8051 || avg_batch_loss: 0.3749 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0468 || batch_loss: 0.8275 || avg_batch_loss: 0.7249 || batch_acc: 0.7500 || avg_batch_acc: 0.7892 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0160 || batch_loss: 0.8092 || avg_batch_loss: 0.7252 || batch_acc: 0.1875 || avg_batch_acc: 0.7870 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7252 and acc: 0.7892\n","              precision    recall  f1-score   support\n","\n","           0     0.8759    0.9148    0.8949      3193\n","           1     0.8503    0.8256    0.8378       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3883    0.3593    0.3732       295\n","           4     0.4624    0.4831    0.4725       356\n","           5     0.5062    0.3974    0.4453       307\n","\n","    accuracy                         0.7892      4388\n","   macro avg     0.5138    0.4967    0.5039      4388\n","weighted avg     0.7697    0.7892    0.7786      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0488 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0161 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_19:32:51.390847\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of test data: 4392\n","n_batches of test data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0932 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0400 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_19:32:51.390847\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77798,"status":"ok","timestamp":1610570874014,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"CmxPfj_kfePr","outputId":"468a212f-74b2-43a5-c093-33455fd099f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:46:39.606226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0458 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0154 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_20:47:35.795383\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/xlm-roberta-base/text_raw"]},{"cell_type":"markdown","metadata":{"id":"XOEFpM1-SLil"},"source":["### run-3"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1409127,"status":"ok","timestamp":1610570417842,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"P1lNK6WoSNpK","outputId":"79ee295e-4b6e-407f-8ff9-07eee8066d38"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 19:46:27.868857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/train.jsonl, mode:train, #examples:35139\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/test.jsonl, mode:test, #examples:4392\n","100% 35139/35139 [00:00\u003c00:00, 1850576.93it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 25425, 'not-Tamil': 1454, 'Offensive_Targeted_Insult_Other': 454, 'Offensive_Targeted_Insult_Group': 2557, 'Offensive_Untargetede': 2906, 'Offensive_Targeted_Insult_Individual': 2343}\n","\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","epoch:  0\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [\u003e              ] 0% || batch_time: 0.4423 || batch_loss: 1.7267 || avg_batch_loss: 1.7267 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3835 || batch_loss: 0.9145 || avg_batch_loss: 0.7749 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2549 || batch_loss: 0.0848 || avg_batch_loss: 0.7746 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0487 || batch_loss: 0.5550 || avg_batch_loss: 0.6398 || batch_acc: 0.8125 || avg_batch_acc: 0.7783 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0164 || batch_loss: 1.0489 || avg_batch_loss: 0.6413 || batch_acc: 0.1875 || avg_batch_acc: 0.7761 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6413 and acc: 0.7783\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.8384    0.9295    0.8816      3193\n","           1     0.7196    0.8953    0.7979       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.4000    0.2847    0.3327       295\n","           4     0.4923    0.2697    0.3485       356\n","           5     0.4934    0.3681    0.4216       307\n","\n","    accuracy                         0.7783      4388\n","   macro avg     0.4906    0.4579    0.4637      4388\n","weighted avg     0.7397    0.7783    0.7529      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.4270 || batch_loss: 0.2617 || avg_batch_loss: 0.5914 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2606 || batch_loss: 0.0432 || avg_batch_loss: 0.5911 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0477 || batch_loss: 0.6478 || avg_batch_loss: 0.6415 || batch_acc: 0.7500 || avg_batch_acc: 0.7817 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0160 || batch_loss: 0.8776 || avg_batch_loss: 0.6424 || batch_acc: 0.1875 || avg_batch_acc: 0.7795 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6424 and acc: 0.7817\n","              precision    recall  f1-score   support\n","\n","           0     0.8509    0.9261    0.8869      3193\n","           1     0.8197    0.8721    0.8451       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3435    0.3831    0.3622       295\n","           4     0.5095    0.3006    0.3781       356\n","           5     0.5393    0.3355    0.4137       307\n","\n","    accuracy                         0.7817      4388\n","   macro avg     0.5105    0.4695    0.4810      4388\n","weighted avg     0.7535    0.7817    0.7625      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.4335 || batch_loss: 0.2859 || avg_batch_loss: 0.5046 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2502 || batch_loss: 0.8175 || avg_batch_loss: 0.5048 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0475 || batch_loss: 0.6195 || avg_batch_loss: 0.6387 || batch_acc: 0.6875 || avg_batch_acc: 0.7872 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0159 || batch_loss: 0.7937 || avg_batch_loss: 0.6393 || batch_acc: 0.1875 || avg_batch_acc: 0.7850 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6393 and acc: 0.7871\n","              precision    recall  f1-score   support\n","\n","           0     0.8802    0.9064    0.8931      3193\n","           1     0.8427    0.8721    0.8571       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.4015    0.3661    0.3830       295\n","           4     0.4463    0.4551    0.4506       356\n","           5     0.4828    0.4560    0.4690       307\n","\n","    accuracy                         0.7871      4388\n","   macro avg     0.5089    0.5093    0.5088      4388\n","weighted avg     0.7705    0.7871    0.7786      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.4035 || batch_loss: 0.3941 || avg_batch_loss: 0.4357 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2585 || batch_loss: 0.0388 || avg_batch_loss: 0.4356 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0499 || batch_loss: 0.7564 || avg_batch_loss: 0.6564 || batch_acc: 0.6250 || avg_batch_acc: 0.7781 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0185 || batch_loss: 0.9104 || avg_batch_loss: 0.6573 || batch_acc: 0.1875 || avg_batch_acc: 0.7759 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6573 and acc: 0.7780\n","              precision    recall  f1-score   support\n","\n","           0     0.8826    0.8951    0.8888      3193\n","           1     0.8614    0.8314    0.8462       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3676    0.4000    0.3831       295\n","           4     0.4171    0.4803    0.4465       356\n","           5     0.4901    0.4039    0.4429       307\n","\n","    accuracy                         0.7780      4388\n","   macro avg     0.5031    0.5018    0.5012      4388\n","weighted avg     0.7689    0.7780    0.7729      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.2402 || batch_loss: 0.6813 || avg_batch_loss: 0.3824 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.1704 || batch_loss: 0.2809 || avg_batch_loss: 0.3826 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.1729 || batch_loss: 0.0421 || avg_batch_loss: 0.3824 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3324 || batch_loss: 0.3061 || avg_batch_loss: 0.3823 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2584 || batch_loss: 0.3220 || avg_batch_loss: 0.3823 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0471 || batch_loss: 0.7236 || avg_batch_loss: 0.7051 || batch_acc: 0.6875 || avg_batch_acc: 0.7838 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0157 || batch_loss: 0.8295 || avg_batch_loss: 0.7055 || batch_acc: 0.1875 || avg_batch_acc: 0.7816 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7055 and acc: 0.7837\n","              precision    recall  f1-score   support\n","\n","           0     0.8762    0.9089    0.8922      3193\n","           1     0.8563    0.8314    0.8437       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3830    0.3661    0.3744       295\n","           4     0.4258    0.4270    0.4264       356\n","           5     0.4963    0.4365    0.4645       307\n","\n","    accuracy                         0.7837      4388\n","   macro avg     0.5063    0.4950    0.5002      4388\n","weighted avg     0.7662    0.7837    0.7746      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0468 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0160 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_20:39:40.245113\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of test data: 4392\n","n_batches of test data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0885 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0434 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_20:39:40.245113\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run3"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70705,"status":"ok","timestamp":1610570627196,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"h5yXHg-3fBXt","outputId":"3303c5c7-78e4-43f6-9ded-c41c56f6b895"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:42:42.880804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","number of parameters (all, trainable) in your model: (278048262, 278048262)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0470 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0179 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw/2021-01-13_20:43:29.681573\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/xlm-roberta-base/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run3 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/xlm-roberta-base/text_raw"]},{"cell_type":"markdown","metadata":{"id":"-GhcWdBzfs7t"},"source":["# mbert w/ MLM-pretrained"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":976,"status":"ok","timestamp":1610609340330,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"3HJZyyOQf2Qr","outputId":"71e40353-2f4b-4939-97c8-72e77192e387"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/codemixed/scripts\n"]}],"source":["%cd /content/codemixed/scripts/"]},{"cell_type":"markdown","metadata":{"id":"2LJiQP8ef2lK"},"source":["### run-1"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":644492,"status":"ok","timestamp":1610571519784,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"hwhmrDY1gEIg","outputId":"b6fb4829-46f4-4a5a-9511-b774fbd9db72"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:47:57.977295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/train.jsonl, mode:train, #examples:6217\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/test.jsonl, mode:test, #examples:778\n","100% 6217/6217 [00:00\u003c00:00, 1839056.91it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 3544, 'not-Kannada': 1522, 'Offensive_Targeted_Insult_Group': 329, 'Offensive_Targeted_Insult_Other': 123, 'Offensive_Targeted_Insult_Individual': 487, 'Offensive_Untargetede': 212}\n","\n","Downloading: 100% 625/625 [00:00\u003c00:00, 989kB/s]\n","Downloading: 100% 996k/996k [00:00\u003c00:00, 24.3MB/s]\n","Downloading: 100% 714M/714M [00:12\u003c00:00, 56.0MB/s]\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/bert-base-multilingual-cased/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/bert-base-multilingual-cased//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","epoch:  0\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [\u003e              ] 0% || batch_time: 0.2691 || batch_loss: 1.7649 || avg_batch_loss: 1.7649 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3678 || batch_loss: 0.7397 || avg_batch_loss: 1.0075 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2452 || batch_loss: 0.8079 || avg_batch_loss: 1.0070 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0556 || batch_loss: 0.6713 || avg_batch_loss: 0.8935 || batch_acc: 0.7500 || avg_batch_acc: 0.7096 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0359 || batch_loss: 0.9859 || avg_batch_loss: 0.8954 || batch_acc: 0.3125 || avg_batch_acc: 0.7015 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8954 and acc: 0.7079\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.6972    0.8920    0.7827       426\n","           1     0.7735    0.7330    0.7527       191\n","           2     0.0000    0.0000    0.0000        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5882    0.4545    0.5128        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7079       777\n","   macro avg     0.3432    0.3466    0.3414       777\n","weighted avg     0.6224    0.7079    0.6577       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.4387 || batch_loss: 0.4938 || avg_batch_loss: 0.7371 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3030 || batch_loss: 0.5001 || avg_batch_loss: 0.7364 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0560 || batch_loss: 0.5246 || avg_batch_loss: 0.8231 || batch_acc: 0.8125 || avg_batch_acc: 0.7161 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0356 || batch_loss: 0.5585 || avg_batch_loss: 0.8177 || batch_acc: 0.3750 || avg_batch_acc: 0.7092 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8177 and acc: 0.7156\n","              precision    recall  f1-score   support\n","\n","           0     0.7398    0.8474    0.7899       426\n","           1     0.7246    0.7853    0.7538       191\n","           2     0.5000    0.1778    0.2623        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5606    0.5606    0.5606        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7156       777\n","   macro avg     0.4208    0.3952    0.3944       777\n","weighted avg     0.6603    0.7156    0.6812       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.3034 || batch_loss: 0.5019 || avg_batch_loss: 0.5854 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3086 || batch_loss: 0.2404 || avg_batch_loss: 0.5845 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0553 || batch_loss: 0.6149 || avg_batch_loss: 0.8432 || batch_acc: 0.7500 || avg_batch_acc: 0.7357 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0351 || batch_loss: 0.7092 || avg_batch_loss: 0.8404 || batch_acc: 0.3750 || avg_batch_acc: 0.7283 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8404 and acc: 0.7349\n","              precision    recall  f1-score   support\n","\n","           0     0.7551    0.8615    0.8048       426\n","           1     0.7431    0.8482    0.7922       191\n","           2     0.5294    0.2000    0.2903        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5893    0.5000    0.5410        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7349       777\n","   macro avg     0.4362    0.4016    0.4047       777\n","weighted avg     0.6774    0.7349    0.6988       777\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.2955 || batch_loss: 0.7568 || avg_batch_loss: 0.4521 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2205 || batch_loss: 0.6036 || avg_batch_loss: 0.4525 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0549 || batch_loss: 0.9668 || avg_batch_loss: 0.9110 || batch_acc: 0.7500 || avg_batch_acc: 0.7148 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0393 || batch_loss: 0.7274 || avg_batch_loss: 0.9072 || batch_acc: 0.3750 || avg_batch_acc: 0.7079 \n","\n"," Validation Complete\n","Validation avg_loss: 0.9072 and acc: 0.7143\n","              precision    recall  f1-score   support\n","\n","           0     0.7773    0.8192    0.7977       426\n","           1     0.7415    0.7958    0.7677       191\n","           2     0.3061    0.3333    0.3191        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5270    0.5909    0.5571        66\n","           5     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7143       777\n","   macro avg     0.3920    0.4232    0.4069       777\n","weighted avg     0.6709    0.7143    0.6919       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 99% || batch_time: 0.0560 || batch_loss: 0.3440 || avg_batch_loss: 0.3556 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 99% || batch_time: 0.3082 || batch_loss: 0.0666 || avg_batch_loss: 0.3552 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3345 || batch_loss: 0.5842 || avg_batch_loss: 0.3558 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2832 || batch_loss: 0.3771 || avg_batch_loss: 0.3559 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0549 || batch_loss: 0.9823 || avg_batch_loss: 0.9691 || batch_acc: 0.7500 || avg_batch_acc: 0.7135 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0355 || batch_loss: 0.8731 || avg_batch_loss: 0.9671 || batch_acc: 0.3750 || avg_batch_acc: 0.7066 \n","\n"," Validation Complete\n","Validation avg_loss: 0.9671 and acc: 0.7130\n","              precision    recall  f1-score   support\n","\n","           0     0.7505    0.8474    0.7960       426\n","           1     0.7527    0.7330    0.7427       191\n","           2     0.3800    0.4222    0.4000        45\n","           3     0.0000    0.0000    0.0000        16\n","           4     0.5789    0.5000    0.5366        66\n","           5     0.3333    0.0303    0.0556        33\n","\n","    accuracy                         0.7130       777\n","   macro avg     0.4659    0.4222    0.4218       777\n","weighted avg     0.6818    0.7130    0.6901       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0568 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0363 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/2021-01-13_20:58:29.513050\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw\n","len of test data: 778\n","n_batches of test data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0379 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0284 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/2021-01-13_20:58:29.513050\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/kannada --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40264,"status":"ok","timestamp":1610571560065,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"flkqLw3lgKDB","outputId":"50e53064-234c-4a03-8725-2b548ad1662f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 20:58:42.448619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/dev.jsonl, mode:dev, #examples:777\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0521 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0351 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw/2021-01-13_20:59:14.512491\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/kannada --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/kannada/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/kannada/bert-base-multilingual-cased/text_raw"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1606031,"status":"ok","timestamp":1610573375209,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"N_93yHocjt_a","outputId":"0ca120b7-ac08-4352-d9fb-00ad5a31dcbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 21:02:51.758278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/train.jsonl, mode:train, #examples:16010\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/test.jsonl, mode:test, #examples:2001\n","100% 16010/16010 [00:00\u003c00:00, 1899598.50it/s]\n","Total tokens found: 5\n","token_freq:\n","{'Not_offensive': 14153, 'Offensive_Targeted_Insult_Individual': 239, 'not-malayalam': 1287, 'Offensive_Targeted_Insult_Group': 140, 'Offensive_Untargetede': 191}\n","\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/bert-base-multilingual-cased/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/bert-base-multilingual-cased//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (177857285, 177857285)\n","\n","\n","################\n","epoch:  0\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [\u003e              ] 0% || batch_time: 0.2779 || batch_loss: 1.3777 || avg_batch_loss: 1.3777 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3108 || batch_loss: 0.9458 || avg_batch_loss: 0.3458 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2379 || batch_loss: 0.0951 || avg_batch_loss: 0.3456 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1405 || batch_loss: 0.0602 || avg_batch_loss: 0.2268 || batch_acc: 1.0000 || avg_batch_acc: 0.9350 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0929 || batch_loss: 0.1341 || avg_batch_loss: 0.2260 || batch_acc: 0.8750 || avg_batch_acc: 0.9345 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2260 and acc: 0.9350\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.9393    0.9910    0.9644      1779\n","           1     0.0000    0.0000    0.0000        24\n","           2     0.8689    0.6503    0.7439       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.0000    0.0000    0.0000        20\n","\n","    accuracy                         0.9350      1999\n","   macro avg     0.3616    0.3283    0.3417      1999\n","weighted avg     0.9067    0.9350    0.9190      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.3534 || batch_loss: 0.0136 || avg_batch_loss: 0.1901 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3380 || batch_loss: 0.4595 || avg_batch_loss: 0.1904 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1379 || batch_loss: 0.0150 || avg_batch_loss: 0.1594 || batch_acc: 1.0000 || avg_batch_acc: 0.9521 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0944 || batch_loss: 0.0747 || avg_batch_loss: 0.1588 || batch_acc: 0.8750 || avg_batch_acc: 0.9515 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1588 and acc: 0.9520\n","              precision    recall  f1-score   support\n","\n","           0     0.9643    0.9865    0.9753      1779\n","           1     0.2308    0.1250    0.1622        24\n","           2     0.8854    0.8528    0.8688       163\n","           3     0.0000    0.0000    0.0000        13\n","           4     0.6667    0.3000    0.4138        20\n","\n","    accuracy                         0.9520      1999\n","   macro avg     0.5494    0.4529    0.4840      1999\n","weighted avg     0.9398    0.9520    0.9449      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.3279 || batch_loss: 0.0675 || avg_batch_loss: 0.1016 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2685 || batch_loss: 0.0476 || avg_batch_loss: 0.1015 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1390 || batch_loss: 0.0110 || avg_batch_loss: 0.1544 || batch_acc: 1.0000 || avg_batch_acc: 0.9607 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0943 || batch_loss: 0.0918 || avg_batch_loss: 0.1539 || batch_acc: 0.8750 || avg_batch_acc: 0.9600 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1539 and acc: 0.9605\n","              precision    recall  f1-score   support\n","\n","           0     0.9771    0.9837    0.9804      1779\n","           1     0.5625    0.3750    0.4500        24\n","           2     0.9085    0.9141    0.9113       163\n","           3     0.5000    0.2308    0.3158        13\n","           4     0.4091    0.4500    0.4286        20\n","\n","    accuracy                         0.9605      1999\n","   macro avg     0.6714    0.5907    0.6172      1999\n","weighted avg     0.9578    0.9605    0.9585      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.6005 || batch_loss: 0.3172 || avg_batch_loss: 0.0577 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2492 || batch_loss: 0.0684 || avg_batch_loss: 0.0577 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1412 || batch_loss: 0.0022 || avg_batch_loss: 0.1569 || batch_acc: 1.0000 || avg_batch_acc: 0.9647 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0943 || batch_loss: 0.0813 || avg_batch_loss: 0.1563 || batch_acc: 0.8750 || avg_batch_acc: 0.9640 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1563 and acc: 0.9645\n","              precision    recall  f1-score   support\n","\n","           0     0.9777    0.9865    0.9821      1779\n","           1     0.7143    0.4167    0.5263        24\n","           2     0.9193    0.9080    0.9136       163\n","           3     1.0000    0.3077    0.4706        13\n","           4     0.4400    0.5500    0.4889        20\n","\n","    accuracy                         0.9645      1999\n","   macro avg     0.8103    0.6338    0.6763      1999\n","weighted avg     0.9646    0.9645    0.9628      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 3\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 3\n","\n","\n","################\n","epoch:  4\n","len of train data: 16010\n","n_batches of train data: 1001\n","Percent: [--------------\u003e] 100% || batch_time: 0.2425 || batch_loss: 0.0013 || avg_batch_loss: 0.0348 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.1397 || batch_loss: 0.1615 || avg_batch_loss: 0.0350 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.4266 || batch_loss: 0.0161 || avg_batch_loss: 0.0350 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2250 || batch_loss: 0.0034 || avg_batch_loss: 0.0350 || batch_acc: -1.0000 \n","\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1399 || batch_loss: 0.0017 || avg_batch_loss: 0.1610 || batch_acc: 1.0000 || avg_batch_acc: 0.9667 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0951 || batch_loss: 0.0839 || avg_batch_loss: 0.1604 || batch_acc: 0.8750 || avg_batch_acc: 0.9660 \n","\n"," Validation Complete\n","Validation avg_loss: 0.1604 and acc: 0.9665\n","              precision    recall  f1-score   support\n","\n","           0     0.9804    0.9865    0.9835      1779\n","           1     0.7692    0.4167    0.5405        24\n","           2     0.9036    0.9202    0.9119       163\n","           3     1.0000    0.3077    0.4706        13\n","           4     0.5000    0.6500    0.5652        20\n","\n","    accuracy                         0.9665      1999\n","   macro avg     0.8307    0.6562    0.6943      1999\n","weighted avg     0.9670    0.9665    0.9648      1999\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 4\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 4\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1432 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0942 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/2021-01-13_21:29:09.591297\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw\n","len of test data: 2001\n","n_batches of test data: 126\n","Percent: [--------------\u003e] 99% || batch_time: 0.0598 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0230 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/2021-01-13_21:29:09.591297\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/malayalam --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32810,"status":"ok","timestamp":1610573408035,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"-0xgpBAtjz2A","outputId":"a366bf2b-4007-41c6-9caa-f5b8a4999d81"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 21:29:41.928719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/malayalam/dev.jsonl, mode:dev, #examples:1999\n","number of parameters (all, trainable) in your model: (177857285, 177857285)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw\n","len of dev data: 1999\n","n_batches of dev data: 125\n","Percent: [--------------\u003e] 99% || batch_time: 0.1387 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0924 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw/2021-01-13_21:29:55.757311\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/malayalam --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/malayalam/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/malayalam/bert-base-multilingual-cased/text_raw"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3569831,"status":"ok","timestamp":1610576977868,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"09-TN1HakW2E","outputId":"be45fab4-eac1-4f5b-b249-95cc6c81fef0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 21:30:11.290498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/train.jsonl, mode:train, #examples:35139\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/test.jsonl, mode:test, #examples:4392\n","100% 35139/35139 [00:00\u003c00:00, 1897317.82it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 25425, 'not-Tamil': 1454, 'Offensive_Targeted_Insult_Other': 454, 'Offensive_Targeted_Insult_Group': 2557, 'Offensive_Untargetede': 2906, 'Offensive_Targeted_Insult_Individual': 2343}\n","\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","epoch:  0\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [\u003e              ] 0% || batch_time: 0.2749 || batch_loss: 1.6813 || avg_batch_loss: 1.6813 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.4245 || batch_loss: 0.8107 || avg_batch_loss: 0.7519 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.1959 || batch_loss: 0.7411 || avg_batch_loss: 0.7519 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0810 || batch_loss: 0.6872 || avg_batch_loss: 0.6425 || batch_acc: 0.6875 || avg_batch_acc: 0.7828 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0164 || batch_loss: 1.0087 || avg_batch_loss: 0.6439 || batch_acc: 0.1875 || avg_batch_acc: 0.7807 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6439 and acc: 0.7828\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.8393    0.9502    0.8913      3193\n","           1     0.9122    0.7849    0.8438       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.5119    0.1458    0.2269       295\n","           4     0.3819    0.4635    0.4188       356\n","           5     0.5321    0.1889    0.2788       307\n","\n","    accuracy                         0.7828      4388\n","   macro avg     0.5296    0.4222    0.4433      4388\n","weighted avg     0.7491    0.7828    0.7504      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3438 || batch_loss: 0.5498 || avg_batch_loss: 0.5578 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2216 || batch_loss: 0.8556 || avg_batch_loss: 0.5580 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0826 || batch_loss: 0.6851 || avg_batch_loss: 0.6537 || batch_acc: 0.6250 || avg_batch_acc: 0.7730 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0195 || batch_loss: 0.8991 || avg_batch_loss: 0.6546 || batch_acc: 0.1875 || avg_batch_acc: 0.7709 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6546 and acc: 0.7730\n","              precision    recall  f1-score   support\n","\n","           0     0.8742    0.9035    0.8886      3193\n","           1     0.7718    0.9244    0.8413       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3656    0.4102    0.3866       295\n","           4     0.3795    0.4775    0.4229       356\n","           5     0.5534    0.1857    0.2780       307\n","\n","    accuracy                         0.7730      4388\n","   macro avg     0.4908    0.4836    0.4696      4388\n","weighted avg     0.7605    0.7730    0.7594      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 0(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  2\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3220 || batch_loss: 0.8523 || avg_batch_loss: 0.4304 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2421 || batch_loss: 0.0103 || avg_batch_loss: 0.4302 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0841 || batch_loss: 0.4716 || avg_batch_loss: 0.7251 || batch_acc: 0.8750 || avg_batch_acc: 0.7831 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0168 || batch_loss: 0.9407 || avg_batch_loss: 0.7258 || batch_acc: 0.1875 || avg_batch_acc: 0.7809 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7258 and acc: 0.7830\n","              precision    recall  f1-score   support\n","\n","           0     0.8478    0.9367    0.8900      3193\n","           1     0.8343    0.8198    0.8270       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3955    0.2949    0.3379       295\n","           4     0.4626    0.3652    0.4082       356\n","           5     0.4579    0.2834    0.3501       307\n","\n","    accuracy                         0.7830      4388\n","   macro avg     0.4997    0.4500    0.4689      4388\n","weighted avg     0.7458    0.7830    0.7604      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.2878 || batch_loss: 0.5860 || avg_batch_loss: 0.3182 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.1891 || batch_loss: 0.0057 || avg_batch_loss: 0.3180 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0823 || batch_loss: 0.5756 || avg_batch_loss: 0.8444 || batch_acc: 0.8125 || avg_batch_acc: 0.7785 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0160 || batch_loss: 0.9981 || avg_batch_loss: 0.8450 || batch_acc: 0.1875 || avg_batch_acc: 0.7764 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8450 and acc: 0.7785\n","              precision    recall  f1-score   support\n","\n","           0     0.8591    0.9239    0.8903      3193\n","           1     0.8438    0.7849    0.8133       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3694    0.3356    0.3517       295\n","           4     0.4218    0.4017    0.4115       356\n","           5     0.4759    0.2899    0.3603       307\n","\n","    accuracy                         0.7785      4388\n","   macro avg     0.4950    0.4560    0.4712      4388\n","weighted avg     0.7505    0.7785    0.7620      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.0601 || batch_loss: 0.1875 || avg_batch_loss: 0.2395 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3744 || batch_loss: 0.2190 || avg_batch_loss: 0.2395 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3833 || batch_loss: 0.2808 || avg_batch_loss: 0.2395 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2671 || batch_loss: 0.1254 || avg_batch_loss: 0.2395 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.1869 || batch_loss: 0.0089 || avg_batch_loss: 0.2394 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0840 || batch_loss: 0.5336 || avg_batch_loss: 0.9045 || batch_acc: 0.8125 || avg_batch_acc: 0.7753 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0185 || batch_loss: 1.0808 || avg_batch_loss: 0.9051 || batch_acc: 0.1875 || avg_batch_acc: 0.7732 \n","\n"," Validation Complete\n","Validation avg_loss: 0.9051 and acc: 0.7753\n","              precision    recall  f1-score   support\n","\n","           0     0.8595    0.9161    0.8869      3193\n","           1     0.8198    0.8198    0.8198       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3725    0.3119    0.3395       295\n","           4     0.4116    0.3989    0.4051       356\n","           5     0.4615    0.3322    0.3864       307\n","\n","    accuracy                         0.7753      4388\n","   macro avg     0.4875    0.4631    0.4729      4388\n","weighted avg     0.7483    0.7753    0.7602      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 2(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0831 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0158 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-13_22:28:47.260854\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of test data: 4392\n","n_batches of test data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0980 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0623 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-13_22:28:47.260854\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51361,"status":"ok","timestamp":1610577029247,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"JSvn_WXQkXGZ","outputId":"b40a08f3-4382-406a-be06-276ecafa0afe"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-13 22:29:42.288606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0845 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0186 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-13_22:30:03.632342\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run1 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run1/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw"]},{"cell_type":"markdown","metadata":{"id":"kNXBqs9rf22J"},"source":["### run-3"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3059,"status":"ok","timestamp":1610609319645,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"x6TaeE3gyry9"},"outputs":[],"source":["# !rm -r /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6Yg8IG5Kknz6"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-14 07:29:09.387176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/train.jsonl, mode:train, #examples:35139\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/test.jsonl, mode:test, #examples:4392\n","100% 35139/35139 [00:00\u003c00:00, 1555516.66it/s]\n","Total tokens found: 6\n","token_freq:\n","{'Not_offensive': 25425, 'not-Tamil': 1454, 'Offensive_Targeted_Insult_Other': 454, 'Offensive_Targeted_Insult_Group': 2557, 'Offensive_Untargetede': 2906, 'Offensive_Targeted_Insult_Individual': 2343}\n","\n","Downloading: 100% 625/625 [00:00\u003c00:00, 968kB/s]\n","Downloading: 100% 996k/996k [00:00\u003c00:00, 32.2MB/s]\n","Downloading: 100% 714M/714M [00:07\u003c00:00, 92.4MB/s]\n","\n","Loading weights from args.custom_pretrained_path:/content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/\n","WARNING !!!\n","Following 4 keys are not updated from /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased//pytorch_model.bin\n","  →→ ['bert_model.pooler.dense.weight', 'bert_model.pooler.dense.bias', 'linear.weight', 'linear.bias']\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","epoch:  0\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [\u003e              ] 0% || batch_time: 0.4849 || batch_loss: 1.5962 || avg_batch_loss: 1.5962 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.3630 || batch_loss: 0.8334 || avg_batch_loss: 0.7466 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.1870 || batch_loss: 0.3756 || avg_batch_loss: 0.7465 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0833 || batch_loss: 0.7029 || avg_batch_loss: 0.6350 || batch_acc: 0.7500 || avg_batch_acc: 0.7803 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0158 || batch_loss: 1.1331 || avg_batch_loss: 0.6368 || batch_acc: 0.1875 || avg_batch_acc: 0.7782 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6368 and acc: 0.7803\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.8121    0.9665    0.8826      3193\n","           1     0.8528    0.8081    0.8299       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.5500    0.1119    0.1859       295\n","           4     0.4468    0.2949    0.3553       356\n","           5     0.4692    0.1987    0.2792       307\n","\n","    accuracy                         0.7803      4388\n","   macro avg     0.5218    0.3967    0.4221      4388\n","weighted avg     0.7304    0.7803    0.7356      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3513 || batch_loss: 0.9236 || avg_batch_loss: 0.5611 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.1910 || batch_loss: 1.5817 || avg_batch_loss: 0.5616 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0827 || batch_loss: 0.5551 || avg_batch_loss: 0.6340 || batch_acc: 0.8125 || avg_batch_acc: 0.7954 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0157 || batch_loss: 0.9028 || avg_batch_loss: 0.6349 || batch_acc: 0.1875 || avg_batch_acc: 0.7932 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6349 and acc: 0.7954\n","              precision    recall  f1-score   support\n","\n","           0     0.8376    0.9593    0.8943      3193\n","           1     0.8790    0.8023    0.8389       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.5753    0.1424    0.2283       295\n","           4     0.4733    0.3989    0.4329       356\n","           5     0.5224    0.3420    0.4134       307\n","\n","    accuracy                         0.7954      4388\n","   macro avg     0.5479    0.4408    0.4680      4388\n","weighted avg     0.7576    0.7954    0.7630      4388\n","\n","Model saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.4182 || batch_loss: 0.8860 || avg_batch_loss: 0.4375 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2008 || batch_loss: 0.8207 || avg_batch_loss: 0.4377 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0829 || batch_loss: 0.6007 || avg_batch_loss: 0.6973 || batch_acc: 0.8125 || avg_batch_acc: 0.7879 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0162 || batch_loss: 0.9641 || avg_batch_loss: 0.6983 || batch_acc: 0.1875 || avg_batch_acc: 0.7857 \n","\n"," Validation Complete\n","Validation avg_loss: 0.6983 and acc: 0.7878\n","              precision    recall  f1-score   support\n","\n","           0     0.8573    0.9317    0.8930      3193\n","           1     0.8268    0.8605    0.8433       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3986    0.3729    0.3853       295\n","           4     0.4833    0.3652    0.4160       356\n","           5     0.4845    0.3062    0.3752       307\n","\n","    accuracy                         0.7878      4388\n","   macro avg     0.5084    0.4727    0.4855      4388\n","weighted avg     0.7562    0.7878    0.7688      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  3\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.3204 || batch_loss: 0.2189 || avg_batch_loss: 0.3276 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.1922 || batch_loss: 0.0132 || avg_batch_loss: 0.3274 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0820 || batch_loss: 0.5629 || avg_batch_loss: 0.7990 || batch_acc: 0.7500 || avg_batch_acc: 0.7776 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0163 || batch_loss: 0.9656 || avg_batch_loss: 0.7996 || batch_acc: 0.1875 || avg_batch_acc: 0.7755 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7996 and acc: 0.7776\n","              precision    recall  f1-score   support\n","\n","           0     0.8702    0.9092    0.8893      3193\n","           1     0.8588    0.8488    0.8538       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3950    0.3186    0.3527       295\n","           4     0.3922    0.4242    0.4076       356\n","           5     0.4556    0.3844    0.4170       307\n","\n","    accuracy                         0.7776      4388\n","   macro avg     0.4953    0.4809    0.4867      4388\n","weighted avg     0.7571    0.7776    0.7665      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 35139\n","n_batches of train data: 2197\n","Percent: [--------------\u003e] 100% || batch_time: 0.1477 || batch_loss: 0.2266 || avg_batch_loss: 0.2514 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3127 || batch_loss: 0.6787 || avg_batch_loss: 0.2516 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2404 || batch_loss: 0.0235 || avg_batch_loss: 0.2515 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.3049 || batch_loss: 0.5186 || avg_batch_loss: 0.2516 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2167 || batch_loss: 0.0797 || avg_batch_loss: 0.2515 || batch_acc: -1.0000 \n","\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0831 || batch_loss: 0.5866 || avg_batch_loss: 0.8635 || batch_acc: 0.7500 || avg_batch_acc: 0.7815 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0156 || batch_loss: 0.9918 || avg_batch_loss: 0.8640 || batch_acc: 0.1875 || avg_batch_acc: 0.7793 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8640 and acc: 0.7814\n","              precision    recall  f1-score   support\n","\n","           0     0.8638    0.9214    0.8917      3193\n","           1     0.8614    0.8314    0.8462       172\n","           2     0.0000    0.0000    0.0000        65\n","           3     0.3944    0.3356    0.3626       295\n","           4     0.4207    0.3876    0.4035       356\n","           5     0.4515    0.3485    0.3934       307\n","\n","    accuracy                         0.7814      4388\n","   macro avg     0.4986    0.4708    0.4829      4388\n","weighted avg     0.7545    0.7814    0.7666      4388\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/model.pth.tar\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0851 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0156 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-14_08:28:37.747609\n","\n","\n","################\n","doing inference on test set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of test data: 4392\n","n_batches of test data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0997 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0622 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-14_08:28:37.747609\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev_test --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O8ImGnG5kt26"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-14 08:29:33.101043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","****\n","/content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","****\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/tamil/dev.jsonl, mode:dev, #examples:4388\n","number of parameters (all, trainable) in your model: (177858054, 177858054)\n","\n","\n","################\n","doing inference on dev set\n","in inference...loading model.pth.tar from /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw\n","len of dev data: 4388\n","n_batches of dev data: 275\n","Percent: [--------------\u003e] 100% || batch_time: 0.0854 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0187 \n","\n","\n","(NEW!) saving predictions in the folder: /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw/2021-01-14_08:30:04.940794\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode dev --model-name bert-base-multilingual-cased --text-type \"\" --dataset-name eacl2021/offeval/tamil --custom-pretrained-path /content/drive/MyDrive/eacl2021/pretraining/offeval/tamil/bert-base-multilingual-cased/ --checkpoint-save-root-dir /content/drive/MyDrive/eacl2021/checkpoints/run3 --eval-ckpt-path /content/drive/MyDrive/eacl2021/checkpoints/run3/eacl2021/offeval/tamil/bert-base-multilingual-cased/text_raw"]},{"cell_type":"markdown","metadata":{"id":"lXMQuDqsvCs9"},"source":["# hierarchical"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":589911,"status":"ok","timestamp":1610105661748,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"AJzrcTC8vBxk","outputId":"8d09526c-eae6-4981-bf92-d873289926f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-08 11:24:37.704435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/lang_classy/train.jsonl, mode:train, #examples:6217\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/lang_classy/dev.jsonl, mode:dev, #examples:777\n","100% 6217/6217 [00:00\u003c00:00, 1894919.55it/s]\n","Total tokens found: 2\n","token_freq:\n","{'lang': 4695, 'not_lang': 1522}\n","\n","Downloading: 100% 512/512 [00:00\u003c00:00, 817kB/s]\n","Downloading: 100% 5.07M/5.07M [00:00\u003c00:00, 52.4MB/s]\n","Downloading: 100% 1.12G/1.12G [00:12\u003c00:00, 90.4MB/s]\n","number of parameters (all, trainable) in your model: (278045186, 278045186)\n","\n","\n","################\n","epoch:  0\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [\u003e              ] 0% || batch_time: 0.2409 || batch_loss: 0.6780 || avg_batch_loss: 0.6780 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.4288 || batch_loss: 0.7835 || avg_batch_loss: 0.4023 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2832 || batch_loss: 0.3308 || avg_batch_loss: 0.4021 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0481 || batch_loss: 0.4986 || avg_batch_loss: 0.3375 || batch_acc: 0.9375 || avg_batch_acc: 0.8724 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0303 || batch_loss: 0.4905 || avg_batch_loss: 0.3406 || batch_acc: 0.4375 || avg_batch_acc: 0.8635 \n","\n"," Validation Complete\n","Validation avg_loss: 0.3406 and acc: 0.8713\n","              precision    recall  f1-score   support\n","\n","           0     0.9355    0.8908    0.9126       586\n","           1     0.7078    0.8115    0.7561       191\n","\n","    accuracy                         0.8713       777\n","   macro avg     0.8216    0.8512    0.8343       777\n","weighted avg     0.8795    0.8713    0.8741       777\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.4028 || batch_loss: 0.2116 || avg_batch_loss: 0.2940 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3563 || batch_loss: 0.1513 || avg_batch_loss: 0.2937 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0515 || batch_loss: 0.3711 || avg_batch_loss: 0.2661 || batch_acc: 0.8750 || avg_batch_acc: 0.8867 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0310 || batch_loss: 0.4308 || avg_batch_loss: 0.2695 || batch_acc: 0.3750 || avg_batch_acc: 0.8763 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2695 and acc: 0.8842\n","              precision    recall  f1-score   support\n","\n","           0     0.9247    0.9215    0.9231       586\n","           1     0.7617    0.7696    0.7656       191\n","\n","    accuracy                         0.8842       777\n","   macro avg     0.8432    0.8456    0.8444       777\n","weighted avg     0.8846    0.8842    0.8844       777\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.3618 || batch_loss: 0.2515 || avg_batch_loss: 0.2482 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2706 || batch_loss: 0.6415 || avg_batch_loss: 0.2492 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0543 || batch_loss: 0.3579 || avg_batch_loss: 0.2783 || batch_acc: 0.9375 || avg_batch_acc: 0.8737 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0320 || batch_loss: 0.2258 || avg_batch_loss: 0.2772 || batch_acc: 0.5000 || avg_batch_acc: 0.8661 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2772 and acc: 0.8739\n","              precision    recall  f1-score   support\n","\n","           0     0.9192    0.9130    0.9161       586\n","           1     0.7385    0.7539    0.7461       191\n","\n","    accuracy                         0.8739       777\n","   macro avg     0.8289    0.8334    0.8311       777\n","weighted avg     0.8748    0.8739    0.8743       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  3\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 100% || batch_time: 0.4630 || batch_loss: 0.3871 || avg_batch_loss: 0.2193 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2978 || batch_loss: 0.2599 || avg_batch_loss: 0.2194 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0515 || batch_loss: 0.3196 || avg_batch_loss: 0.2788 || batch_acc: 0.8750 || avg_batch_acc: 0.8724 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0346 || batch_loss: 0.1892 || avg_batch_loss: 0.2770 || batch_acc: 0.5000 || avg_batch_acc: 0.8648 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2770 and acc: 0.8726\n","              precision    recall  f1-score   support\n","\n","           0     0.9264    0.9027    0.9144       586\n","           1     0.7233    0.7801    0.7506       191\n","\n","    accuracy                         0.8726       777\n","   macro avg     0.8249    0.8414    0.8325       777\n","weighted avg     0.8765    0.8726    0.8742       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 6217\n","n_batches of train data: 389\n","Percent: [--------------\u003e] 99% || batch_time: 0.1733 || batch_loss: 0.1298 || avg_batch_loss: 0.2057 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 99% || batch_time: 0.0383 || batch_loss: 0.2197 || avg_batch_loss: 0.2054 || batch_acc: -1.0000 Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.4331 || batch_loss: 0.2226 || avg_batch_loss: 0.2055 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2570 || batch_loss: 0.2690 || avg_batch_loss: 0.2056 || batch_acc: -1.0000 \n","\n","len of dev data: 777\n","n_batches of dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0518 || batch_loss: 0.3439 || avg_batch_loss: 0.2827 || batch_acc: 0.9375 || avg_batch_acc: 0.8776 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0332 || batch_loss: 0.2516 || avg_batch_loss: 0.2821 || batch_acc: 0.5000 || avg_batch_acc: 0.8699 \n","\n"," Validation Complete\n","Validation avg_loss: 0.2821 and acc: 0.8777\n","              precision    recall  f1-score   support\n","\n","           0     0.9197    0.9181    0.9189       586\n","           1     0.7500    0.7539    0.7520       191\n","\n","    accuracy                         0.8777       777\n","   macro avg     0.8348    0.8360    0.8354       777\n","weighted avg     0.8780    0.8777    0.8778       777\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","in testing...loading model.pth.tar from ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw\n","len of train_dev data: 777\n","n_batches of train_dev data: 49\n","Percent: [--------------\u003e] 98% || batch_time: 0.0504 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0345 \n","\n","\n","(NEW!) saving predictions in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/2021-01-08_11:34:17.004178\n","\n","(NEW!) saving errors files in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/lang_classy/xlm-roberta-base/text_raw/2021-01-08_11:34:17.004178\n","\n","              precision    recall  f1-score   support\n","\n","        lang     0.9247    0.9215    0.9231       586\n","    not_lang     0.7617    0.7696    0.7656       191\n","\n","    accuracy                         0.8842       777\n","   macro avg     0.8432    0.8456    0.8444       777\n","weighted avg     0.8846    0.8842    0.8844       777\n","\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada/hier/lang_classy"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502153,"status":"ok","timestamp":1610106165308,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"2Ef8ABokGx9w","outputId":"72d16fb1-e11f-4053-e241-a7a277752980"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-08 11:34:26.535991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/non_lang_classy/train.jsonl, mode:train, #examples:4695\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/non_lang_classy/dev.jsonl, mode:dev, #examples:586\n","100% 4695/4695 [00:00\u003c00:00, 1853214.50it/s]\n","Total tokens found: 5\n","token_freq:\n","{'Not_offensive': 3544, 'Offensive_Targeted_Insult_Group': 329, 'Offensive_Targeted_Insult_Other': 123, 'Offensive_Targeted_Insult_Individual': 487, 'Offensive_Untargetede': 212}\n","\n","number of parameters (all, trainable) in your model: (278047493, 278047493)\n","\n","\n","################\n","epoch:  0\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [\u003e              ] 0% || batch_time: 0.2557 || batch_loss: 1.5811 || avg_batch_loss: 1.5811 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.0571 || batch_loss: 0.8569 || avg_batch_loss: 0.9387 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3263 || batch_loss: 1.4176 || avg_batch_loss: 0.9403 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0561 || batch_loss: 1.0912 || avg_batch_loss: 0.8717 || batch_acc: 0.6250 || avg_batch_acc: 0.7257 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0338 || batch_loss: 0.8381 || avg_batch_loss: 0.8708 || batch_acc: 0.5000 || avg_batch_acc: 0.7196 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8708 and acc: 0.7270\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.7442    0.9836    0.8473       426\n","           1     0.0000    0.0000    0.0000        45\n","           2     0.0000    0.0000    0.0000        16\n","           3     0.3043    0.1061    0.1573        66\n","           4     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7270       586\n","   macro avg     0.2097    0.2179    0.2009       586\n","weighted avg     0.5753    0.7270    0.6337       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.0523 || batch_loss: 0.4002 || avg_batch_loss: 0.7789 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3176 || batch_loss: 0.1885 || avg_batch_loss: 0.7769 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0573 || batch_loss: 0.9883 || avg_batch_loss: 0.8123 || batch_acc: 0.6250 || avg_batch_acc: 0.7552 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0338 || batch_loss: 0.8197 || avg_batch_loss: 0.8125 || batch_acc: 0.5000 || avg_batch_acc: 0.7483 \n","\n"," Validation Complete\n","Validation avg_loss: 0.8125 and acc: 0.7560\n","              precision    recall  f1-score   support\n","\n","           0     0.7500    1.0000    0.8571       426\n","           1     0.0000    0.0000    0.0000        45\n","           2     0.0000    0.0000    0.0000        16\n","           3     0.9444    0.2576    0.4048        66\n","           4     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7560       586\n","   macro avg     0.3389    0.2515    0.2524       586\n","weighted avg     0.6516    0.7560    0.6687       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.1944 || batch_loss: 0.5287 || avg_batch_loss: 0.7121 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2744 || batch_loss: 0.6866 || avg_batch_loss: 0.7120 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0609 || batch_loss: 0.8835 || avg_batch_loss: 0.7807 || batch_acc: 0.7500 || avg_batch_acc: 0.7656 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0364 || batch_loss: 0.7210 || avg_batch_loss: 0.7791 || batch_acc: 0.5625 || avg_batch_acc: 0.7601 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7791 and acc: 0.7679\n","              precision    recall  f1-score   support\n","\n","           0     0.7824    0.9789    0.8697       426\n","           1     0.0000    0.0000    0.0000        45\n","           2     0.0000    0.0000    0.0000        16\n","           3     0.6226    0.5000    0.5546        66\n","           4     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7679       586\n","   macro avg     0.2810    0.2958    0.2849       586\n","weighted avg     0.6389    0.7679    0.6947       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.0480 || batch_loss: 0.7158 || avg_batch_loss: 0.6564 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3128 || batch_loss: 0.8409 || avg_batch_loss: 0.6570 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0614 || batch_loss: 0.9710 || avg_batch_loss: 0.7710 || batch_acc: 0.7500 || avg_batch_acc: 0.7778 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0381 || batch_loss: 0.6432 || avg_batch_loss: 0.7675 || batch_acc: 0.5625 || avg_batch_acc: 0.7720 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7675 and acc: 0.7799\n","              precision    recall  f1-score   support\n","\n","           0     0.8046    0.9765    0.8823       426\n","           1     0.0000    0.0000    0.0000        45\n","           2     0.0000    0.0000    0.0000        16\n","           3     0.5942    0.6212    0.6074        66\n","           4     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7799       586\n","   macro avg     0.2798    0.3195    0.2979       586\n","weighted avg     0.6519    0.7799    0.7098       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 3\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 3\n","\n","\n","################\n","epoch:  4\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.1509 || batch_loss: 0.8926 || avg_batch_loss: 0.6223 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2726 || batch_loss: 0.5636 || avg_batch_loss: 0.6221 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0587 || batch_loss: 1.0271 || avg_batch_loss: 0.7900 || batch_acc: 0.6875 || avg_batch_acc: 0.7674 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0339 || batch_loss: 0.6440 || avg_batch_loss: 0.7861 || batch_acc: 0.5625 || avg_batch_acc: 0.7618 \n","\n"," Validation Complete\n","Validation avg_loss: 0.7861 and acc: 0.7696\n","              precision    recall  f1-score   support\n","\n","           0     0.8126    0.9671    0.8832       426\n","           1     0.0000    0.0000    0.0000        45\n","           2     0.0000    0.0000    0.0000        16\n","           3     0.4937    0.5909    0.5379        66\n","           4     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.7696       586\n","   macro avg     0.2613    0.3116    0.2842       586\n","weighted avg     0.6463    0.7696    0.7026       586\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 3(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","in testing...loading model.pth.tar from ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw\n","len of train_dev data: 586\n","n_batches of train_dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0638 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0359 \n","\n","\n","(NEW!) saving predictions in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/2021-01-08_11:42:40.139506\n","\n","(NEW!) saving errors files in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/non_lang_classy/xlm-roberta-base/text_raw/2021-01-08_11:42:40.139506\n","\n","                                      precision    recall  f1-score   support\n","\n","                       Not_offensive     0.8046    0.9765    0.8823       426\n","     Offensive_Targeted_Insult_Group     0.0000    0.0000    0.0000        45\n","     Offensive_Targeted_Insult_Other     0.0000    0.0000    0.0000        16\n","Offensive_Targeted_Insult_Individual     0.5942    0.6212    0.6074        66\n","               Offensive_Untargetede     0.0000    0.0000    0.0000        33\n","\n","                            accuracy                         0.7799       586\n","                           macro avg     0.2798    0.3195    0.2979       586\n","                        weighted avg     0.6519    0.7799    0.7098       586\n","\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada/hier/non_lang_classy"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":991814,"status":"ok","timestamp":1610106654975,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"zown2DflwrH2","outputId":"4ab686c8-e006-4d3c-f8ed-ae75a56d6448"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-08 11:42:49.922318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/off_not_classy/train.jsonl, mode:train, #examples:4695\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/off_not_classy/dev.jsonl, mode:dev, #examples:586\n","100% 4695/4695 [00:00\u003c00:00, 1851994.48it/s]\n","Total tokens found: 2\n","token_freq:\n","{'Not_offensive': 3544, 'Offensive': 1151}\n","\n","number of parameters (all, trainable) in your model: (278045186, 278045186)\n","\n","\n","################\n","epoch:  0\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [\u003e              ] 0% || batch_time: 0.0802 || batch_loss: 0.7453 || avg_batch_loss: 0.7453 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 100% || batch_time: 0.0637 || batch_loss: 0.6833 || avg_batch_loss: 0.5626 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3724 || batch_loss: 0.4833 || avg_batch_loss: 0.5624 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0576 || batch_loss: 0.6174 || avg_batch_loss: 0.5190 || batch_acc: 0.6250 || avg_batch_acc: 0.7257 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0352 || batch_loss: 0.5159 || avg_batch_loss: 0.5190 || batch_acc: 0.5000 || avg_batch_acc: 0.7196 \n","\n"," Validation Complete\n","Validation avg_loss: 0.5190 and acc: 0.7270\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.7270    1.0000    0.8419       426\n","           1     0.0000    0.0000    0.0000       160\n","\n","    accuracy                         0.7270       586\n","   macro avg     0.3635    0.5000    0.4209       586\n","weighted avg     0.5285    0.7270    0.6120       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.1863 || batch_loss: 0.5077 || avg_batch_loss: 0.4989 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.2804 || batch_loss: 0.3180 || avg_batch_loss: 0.4983 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0564 || batch_loss: 0.5656 || avg_batch_loss: 0.4886 || batch_acc: 0.6250 || avg_batch_acc: 0.7639 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0341 || batch_loss: 0.4922 || avg_batch_loss: 0.4887 || batch_acc: 0.5000 || avg_batch_acc: 0.7568 \n","\n"," Validation Complete\n","Validation avg_loss: 0.4887 and acc: 0.7645\n","              precision    recall  f1-score   support\n","\n","           0     0.7628    0.9812    0.8583       426\n","           1     0.7895    0.1875    0.3030       160\n","\n","    accuracy                         0.7645       586\n","   macro avg     0.7761    0.5844    0.5807       586\n","weighted avg     0.7701    0.7645    0.7067       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.2080 || batch_loss: 0.5055 || avg_batch_loss: 0.4417 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3350 || batch_loss: 0.3648 || avg_batch_loss: 0.4414 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0585 || batch_loss: 0.6270 || avg_batch_loss: 0.4838 || batch_acc: 0.7500 || avg_batch_acc: 0.7917 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0354 || batch_loss: 0.5431 || avg_batch_loss: 0.4854 || batch_acc: 0.5000 || avg_batch_acc: 0.7838 \n","\n"," Validation Complete\n","Validation avg_loss: 0.4854 and acc: 0.7918\n","              precision    recall  f1-score   support\n","\n","           0     0.7992    0.9531    0.8694       426\n","           1     0.7436    0.3625    0.4874       160\n","\n","    accuracy                         0.7918       586\n","   macro avg     0.7714    0.6578    0.6784       586\n","weighted avg     0.7840    0.7918    0.7651       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 2\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 2\n","\n","\n","################\n","epoch:  3\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.0449 || batch_loss: 0.2601 || avg_batch_loss: 0.4043 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3040 || batch_loss: 0.3917 || avg_batch_loss: 0.4043 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0607 || batch_loss: 0.6452 || avg_batch_loss: 0.4603 || batch_acc: 0.7500 || avg_batch_acc: 0.8038 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0368 || batch_loss: 0.4436 || avg_batch_loss: 0.4599 || batch_acc: 0.5625 || avg_batch_acc: 0.7973 \n","\n"," Validation Complete\n","Validation avg_loss: 0.4599 and acc: 0.8055\n","              precision    recall  f1-score   support\n","\n","           0     0.8291    0.9225    0.8733       426\n","           1     0.7054    0.4938    0.5809       160\n","\n","    accuracy                         0.8055       586\n","   macro avg     0.7672    0.7081    0.7271       586\n","weighted avg     0.7953    0.8055    0.7935       586\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 3\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 3\n","\n","\n","################\n","epoch:  4\n","len of train data: 4695\n","n_batches of train data: 294\n","Percent: [--------------\u003e] 100% || batch_time: 0.1838 || batch_loss: 0.4843 || avg_batch_loss: 0.3743 || batch_acc: -1.0000 \n","Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","Percent: [--------------\u003e] 100% || batch_time: 0.2991 || batch_loss: 0.5600 || avg_batch_loss: 0.3750 || batch_acc: -1.0000 \n","\n","len of dev data: 586\n","n_batches of dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0637 || batch_loss: 0.6481 || avg_batch_loss: 0.4610 || batch_acc: 0.7500 || avg_batch_acc: 0.7986 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0372 || batch_loss: 0.4774 || avg_batch_loss: 0.4615 || batch_acc: 0.5625 || avg_batch_acc: 0.7922 \n","\n"," Validation Complete\n","Validation avg_loss: 0.4615 and acc: 0.8003\n","              precision    recall  f1-score   support\n","\n","           0     0.8280    0.9155    0.8696       426\n","           1     0.6870    0.4938    0.5745       160\n","\n","    accuracy                         0.8003       586\n","   macro avg     0.7575    0.7046    0.7221       586\n","weighted avg     0.7895    0.8003    0.7890       586\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 3(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","in testing...loading model.pth.tar from ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw\n","len of train_dev data: 586\n","n_batches of train_dev data: 37\n","Percent: [--------------\u003e] 97% || batch_time: 0.0599 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0364 \n","\n","\n","(NEW!) saving predictions in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/2021-01-08_11:50:50.646251\n","\n","(NEW!) saving errors files in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/off_not_classy/xlm-roberta-base/text_raw/2021-01-08_11:50:50.646251\n","\n","               precision    recall  f1-score   support\n","\n","Not_offensive     0.8291    0.9225    0.8733       426\n","    Offensive     0.7054    0.4938    0.5809       160\n","\n","     accuracy                         0.8055       586\n","    macro avg     0.7672    0.7081    0.7271       586\n"," weighted avg     0.7953    0.8055    0.7935       586\n","\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada/hier/off_not_classy"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1171769,"status":"ok","timestamp":1610106834933,"user":{"displayName":"Sai Jayanthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQnkLm3AxyRVCP-Cnw1THqolVrxWWHGORvhSM9=s64","userId":"02761850238464772402"},"user_tz":-330},"id":"bVn4Rm9qLiTe","outputId":"0c80dba1-3bb1-4564-eeaf-c222a919d438"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-01-08 11:50:58.216120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","dropping your inputted info about langids_type and setting it to same as text_type\n","../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/off_classy/train.jsonl, mode:train, #examples:1151\n","in read_datasets_jsonl(): path:../datasets/eacl2021/offeval/kannada/hier/off_classy/dev.jsonl, mode:dev, #examples:160\n","100% 1151/1151 [00:00\u003c00:00, 1615136.80it/s]\n","Total tokens found: 4\n","token_freq:\n","{'Offensive_Targeted_Insult_Group': 329, 'Offensive_Targeted_Insult_Other': 123, 'Offensive_Targeted_Insult_Individual': 487, 'Offensive_Untargetede': 212}\n","\n","number of parameters (all, trainable) in your model: (278046724, 278046724)\n","\n","\n","################\n","epoch:  0\n","len of train data: 1151\n","n_batches of train data: 72\n","Percent: [\u003e              ] 1% || batch_time: 0.0742 || batch_loss: 1.4109 || avg_batch_loss: 1.4109 || batch_acc: -1.0000 /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Percent: [--------------\u003e] 99% || batch_time: 0.2007 || batch_loss: 0.9591 || avg_batch_loss: 1.2739 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3501 || batch_loss: 1.2526 || avg_batch_loss: 1.2736 || batch_acc: -1.0000 \n","\n","len of dev data: 160\n","n_batches of dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0917 || batch_loss: 0.9141 || avg_batch_loss: 1.2681 || batch_acc: 0.6875 || avg_batch_acc: 0.4444 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0819 || batch_loss: 1.2268 || avg_batch_loss: 1.2640 || batch_acc: 0.5000 || avg_batch_acc: 0.4500 \n","\n"," Validation Complete\n","Validation avg_loss: 1.2640 and acc: 0.4500\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0     0.4706    0.1778    0.2581        45\n","           1     0.0000    0.0000    0.0000        16\n","           2     0.4476    0.9697    0.6124        66\n","           3     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.4500       160\n","   macro avg     0.2295    0.2869    0.2176       160\n","weighted avg     0.3170    0.4500    0.3252       160\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 0\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 0\n","\n","\n","################\n","epoch:  1\n","len of train data: 1151\n","n_batches of train data: 72\n","Percent: [--------------\u003e] 99% || batch_time: 0.2779 || batch_loss: 1.1474 || avg_batch_loss: 1.2872 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.4311 || batch_loss: 1.2393 || avg_batch_loss: 1.2865 || batch_acc: -1.0000 \n","\n","len of dev data: 160\n","n_batches of dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0926 || batch_loss: 1.0269 || avg_batch_loss: 1.2943 || batch_acc: 0.8125 || avg_batch_acc: 0.4653 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0828 || batch_loss: 1.1610 || avg_batch_loss: 1.2810 || batch_acc: 0.5625 || avg_batch_acc: 0.4750 \n","\n"," Validation Complete\n","Validation avg_loss: 1.2810 and acc: 0.4750\n","              precision    recall  f1-score   support\n","\n","           0     0.5200    0.2889    0.3714        45\n","           1     0.0000    0.0000    0.0000        16\n","           2     0.4667    0.9545    0.6269        66\n","           3     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.4750       160\n","   macro avg     0.2467    0.3109    0.2496       160\n","weighted avg     0.3387    0.4750    0.3630       160\n","\n","Model saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/model.pth.tar in epoch 1\n","label_vocab saved at ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/label_vocab.json in epoch 1\n","\n","\n","################\n","epoch:  2\n","len of train data: 1151\n","n_batches of train data: 72\n","Percent: [--------------\u003e] 99% || batch_time: 0.1447 || batch_loss: 1.1684 || avg_batch_loss: 1.1745 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.4266 || batch_loss: 1.0677 || avg_batch_loss: 1.1730 || batch_acc: -1.0000 \n","\n","len of dev data: 160\n","n_batches of dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0922 || batch_loss: 0.9871 || avg_batch_loss: 1.2148 || batch_acc: 0.5625 || avg_batch_acc: 0.4306 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0873 || batch_loss: 1.0130 || avg_batch_loss: 1.1946 || batch_acc: 0.6875 || avg_batch_acc: 0.4562 \n","\n"," Validation Complete\n","Validation avg_loss: 1.1946 and acc: 0.4562\n","              precision    recall  f1-score   support\n","\n","           0     0.3471    0.9333    0.5060        45\n","           1     0.0000    0.0000    0.0000        16\n","           2     0.7949    0.4697    0.5905        66\n","           3     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.4562       160\n","   macro avg     0.2855    0.3508    0.2741       160\n","weighted avg     0.4255    0.4562    0.3859       160\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  3\n","len of train data: 1151\n","n_batches of train data: 72\n","Percent: [--------------\u003e] 99% || batch_time: 0.2614 || batch_loss: 0.9376 || avg_batch_loss: 1.1527 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.3994 || batch_loss: 0.9576 || avg_batch_loss: 1.1500 || batch_acc: -1.0000 \n","\n","len of dev data: 160\n","n_batches of dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0938 || batch_loss: 0.9869 || avg_batch_loss: 1.1981 || batch_acc: 0.5625 || avg_batch_acc: 0.4306 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0854 || batch_loss: 1.0256 || avg_batch_loss: 1.1809 || batch_acc: 0.6875 || avg_batch_acc: 0.4562 \n","\n"," Validation Complete\n","Validation avg_loss: 1.1809 and acc: 0.4562\n","              precision    recall  f1-score   support\n","\n","           0     0.3471    0.9333    0.5060        45\n","           1     0.0000    0.0000    0.0000        16\n","           2     0.7949    0.4697    0.5905        66\n","           3     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.4562       160\n","   macro avg     0.2855    0.3508    0.2741       160\n","weighted avg     0.4255    0.4562    0.3859       160\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","epoch:  4\n","len of train data: 1151\n","n_batches of train data: 72\n","Percent: [--------------\u003e] 99% || batch_time: 0.2324 || batch_loss: 1.1453 || avg_batch_loss: 1.1416 || batch_acc: -1.0000 \n","Percent: [--------------\u003e] 100% || batch_time: 0.4334 || batch_loss: 1.3570 || avg_batch_loss: 1.1446 || batch_acc: -1.0000 \n","\n","len of dev data: 160\n","n_batches of dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0943 || batch_loss: 0.9527 || avg_batch_loss: 1.1976 || batch_acc: 0.5625 || avg_batch_acc: 0.4444 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0852 || batch_loss: 0.9852 || avg_batch_loss: 1.1764 || batch_acc: 0.6875 || avg_batch_acc: 0.4688 \n","\n"," Validation Complete\n","Validation avg_loss: 1.1764 and acc: 0.4688\n","              precision    recall  f1-score   support\n","\n","           0     0.3559    0.9333    0.5153        45\n","           1     0.0000    0.0000    0.0000        16\n","           2     0.7857    0.5000    0.6111        66\n","           3     0.0000    0.0000    0.0000        33\n","\n","    accuracy                         0.4688       160\n","   macro avg     0.2854    0.3583    0.2816       160\n","weighted avg     0.4242    0.4688    0.3970       160\n","\n","no improvements in results to save a checkpoint\n","checkpoint previously saved during epoch 1(0-base) at: ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/model.pth.tar\n","\n","\n","################\n","in testing...loading model.pth.tar from ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw\n","len of train_dev data: 160\n","n_batches of train_dev data: 10\n","Percent: [-------------\u003e ] 90% || batch_time: 0.0938 \n","Percent: [--------------\u003e] 100% || batch_time: 0.0854 \n","\n","\n","(NEW!) saving predictions in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/2021-01-08_11:53:52.537297\n","\n","(NEW!) saving errors files in the folder: ../checkpoints/eacl2021/offeval/kannada/hier/off_classy/xlm-roberta-base/text_raw/2021-01-08_11:53:52.537297\n","\n","                                      precision    recall  f1-score   support\n","\n","     Offensive_Targeted_Insult_Group     0.5200    0.2889    0.3714        45\n","     Offensive_Targeted_Insult_Other     0.0000    0.0000    0.0000        16\n","Offensive_Targeted_Insult_Individual     0.4667    0.9545    0.6269        66\n","               Offensive_Untargetede     0.0000    0.0000    0.0000        33\n","\n","                            accuracy                         0.4750       160\n","                           macro avg     0.2467    0.3109    0.2496       160\n","                        weighted avg     0.3387    0.4750    0.3630       160\n","\n","complete\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run_eacl2021.py --mode train_dev --model-name xlm-roberta-base --text-type \"\" --dataset-name eacl2021/offeval/kannada/hier/off_classy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDRJW_q2xZWp"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"4BzztbDQwoOX"},"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["FWNUAn35h4LJ","lXMQuDqsvCs9"],"name":"EACL Dravidian Offensive Eval.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}